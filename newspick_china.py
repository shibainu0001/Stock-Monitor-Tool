import requests
from bs4 import BeautifulSoup
# from openai import OpenAI # <--- openai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¯ä¸è¦ã«ãªã‚Šã¾ã™
import time
import random
from datetime import datetime, timedelta
import re
from urllib.parse import quote
import json
from colorama import Fore, Style, init

# ã‚«ãƒ©ãƒ¼å‡ºåŠ›ã®åˆæœŸåŒ–
init(autoreset=True)

class RealTimeNewsAnalyzer:
    def __init__(self, openrouter_api_key):
        # self.client = OpenAI(...) # <--- ã“ã®è¡Œã‚’å‰Šé™¤
        self.openrouter_api_key = openrouter_api_key
        self.base_url = "https://openrouter.ai/api/v1"
        self.target_companies = [
            "XIAOMI", "SEMICONDUCTOR MANUFACTURING", "BYD CO LTD-H", 
            "ALIBABA", "NETEASE", "TENCENT", "TRIP.COM", 
            "LI AUTO CLASS", "BAIDU", "MEITUAN"
        ]
        self.global_analysis_results = []
        self.china_analysis_results = []
        
    def colored_print(self, text, color=Fore.WHITE, style=Style.NORMAL):
        """ã‚«ãƒ©ãƒ¼å‡ºåŠ›ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
        print(f"{style}{color}{text}{Style.RESET_ALL}")
        
    def search_google_news_single(self, query, max_results=25):
        """å˜ä¸€ã‚¯ã‚¨ãƒªã§Google Newsã‹ã‚‰è¨˜äº‹ã‚’å–å¾—"""
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept-Language': 'en-US,en;q=0.9,ja;q=0.8',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        base_url = "https://news.google.com/search"
        params = {
            'q': query,
            'hl': 'en-US',
            'gl': 'US',
            'ceid': 'US:en'
        }
        
        try:
            self.colored_print(f"ğŸ” æ¤œç´¢å®Ÿè¡Œ: \"{query}\"", Fore.CYAN, Style.BRIGHT)
            response = requests.get(base_url, params=params, headers=headers, timeout=20)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            articles = soup.find_all('article')
            
            self.colored_print(f"ğŸ“° ç™ºè¦‹ã•ã‚ŒãŸè¨˜äº‹æ•°: {len(articles)}", Fore.YELLOW)
            
            news_items = []
            one_week_ago = datetime.now() - timedelta(days=7)
            
            for i, article in enumerate(articles[:max_results]):
                try:
                    # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—ï¼ˆè¤‡æ•°ã®ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦è¡Œï¼‰
                    title = ""
                    title_selectors = ['a.JtKRv', 'a[data-n-au]', 'h3 a', 'h4 a', 'article a']
                    for selector in title_selectors:
                        title_tag = article.select_one(selector)
                        if title_tag and title_tag.get_text(strip=True):
                            title = title_tag.get_text(strip=True)
                            break
                    
                    if not title:
                        continue
                    
                    # ãƒªãƒ³ã‚¯å–å¾—
                    link = ""
                    link_selectors = ['a.WwrzSb', 'a.JtKRv', 'a[data-n-au]']
                    for selector in link_selectors:
                        link_tag = article.select_one(selector)
                        if link_tag and link_tag.get('href'):
                            link = link_tag['href']
                            if link.startswith('./'):
                                link = 'https://news.google.com' + link[1:]
                            elif link.startswith('/'):
                                link = 'https://news.google.com' + link
                            break
                    
                    # ã‚½ãƒ¼ã‚¹å–å¾—
                    source = "Unknown"
                    source_selectors = ['div.vr1PYe', '.CEMjEf', 'span.vr1PYe']
                    for selector in source_selectors:
                        source_tag = article.select_one(selector)
                        if source_tag and source_tag.get_text(strip=True):
                            source = source_tag.get_text(strip=True)
                            break
                    
                    # æ™‚é–“å–å¾—
                    time_text = "Unknown"
                    time_tag = article.select_one('time')
                    if time_tag:
                        time_text = time_tag.get_text(strip=True)
                    
                    # ã‚¹ãƒ‹ãƒšãƒƒãƒˆå–å¾—
                    snippet = ""
                    snippet_selectors = ['span.fCU_i', '.Rai5ob', '.xBjCHd', 'div[data-snippet]']
                    for selector in snippet_selectors:
                        snippet_tag = article.select_one(selector)
                        if snippet_tag and snippet_tag.get_text(strip=True):
                            snippet = snippet_tag.get_text(strip=True)
                            break
                    
                    # æ—¥ä»˜æ¨å®š
                    estimated_date = self._estimate_date_from_time_text(time_text)
                    
                    # 1é€±é–“ä»¥å†…ã‹ãƒã‚§ãƒƒã‚¯
                    if estimated_date and estimated_date < one_week_ago:
                        continue
                    
                    news_item = {
                        'title': title,
                        'link': link,
                        'source': source,
                        'time': time_text,
                        'snippet': snippet,
                        'date': estimated_date.strftime('%Y/%m/%d') if estimated_date else 'Unknown',
                        'query': query
                    }
                    
                    news_items.append(news_item)
                    
                except Exception as e:
                    self.colored_print(f"è¨˜äº‹{i+1}ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", Fore.RED)
                    continue
            
            self.colored_print(f"âœ… å–å¾—å®Œäº†: {len(news_items)}ä»¶ã®è¨˜äº‹", Fore.GREEN)
            
            # å–å¾—ã—ãŸè¨˜äº‹ã®ä¸€è¦§è¡¨ç¤ºï¼ˆæœ€åˆã®3ä»¶ï¼‰
            for i, item in enumerate(news_items[:3], 1):
                self.colored_print(f"  {i}. {item['title'][:70]}...", Fore.WHITE)
                self.colored_print(f"    ğŸ“… {item['time']} | ğŸ¢ {item['source']}", Fore.LIGHTBLACK_EX)
            
            if len(news_items) > 3:
                self.colored_print(f"    ... ä»– {len(news_items) - 3} ä»¶", Fore.LIGHTBLACK_EX)
            
            return news_items
            
        except requests.exceptions.RequestException as e:
            self.colored_print(f"âŒ ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}", Fore.RED)
            return []
        except Exception as e:
            self.colored_print(f"âŒ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}", Fore.RED)
            return []

    def _estimate_date_from_time_text(self, time_text):
        """æ™‚é–“ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ—¥ä»˜ã‚’æ¨å®š"""
        if not time_text or time_text == "Unknown":
            return datetime.now()
        
        now = datetime.now()
        time_text_lower = time_text.lower()
        
        try:
            # åˆ†å˜ä½
            if 'minute' in time_text_lower or 'min' in time_text_lower:
                minutes = re.search(r'(\d+)', time_text)
                if minutes:
                    return now - timedelta(minutes=int(minutes.group(1)))
            
            # æ™‚é–“å˜ä½
            elif 'hour' in time_text_lower:
                hours = re.search(r'(\d+)', time_text)
                if hours:
                    return now - timedelta(hours=int(hours.group(1)))
            
            # æ—¥å˜ä½
            elif 'day' in time_text_lower or 'yesterday' in time_text_lower:
                if 'yesterday' in time_text_lower:
                    return now - timedelta(days=1)
                days = re.search(r'(\d+)', time_text)
                if days:
                    return now - timedelta(days=int(days.group(1)))
            
            # é€±å˜ä½
            elif 'week' in time_text_lower:
                weeks = re.search(r'(\d+)', time_text)
                if weeks:
                    return now - timedelta(weeks=int(weeks.group(1)))
    
        except Exception:
            pass
        
        return now

    def analyze_news_with_llm(self, news_data, query, analysis_type="global"):
        """LLMã‚’ä½¿ç”¨ã—ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åˆ†æï¼ˆæœ€å¤§15å›ã®ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰"""
        if not news_data:
            return ""

        today = datetime.now().strftime("%Y/%m/%d")
        news_text = "\n".join([
            f"Date: {item['date']}\nTitle: {item['title']}\nSource: {item['source']}\nSnippet: {item['snippet']}\n---"
            for item in news_data
        ])

        if analysis_type == "global":
            prompt = self._create_global_analysis_prompt(today, query, news_text)
        else:
            prompt = self._create_china_analysis_prompt(today, query, news_text)

        max_retries = 15
        for attempt in range(max_retries):
            try:
                self.colored_print(f"ğŸ¤– LLMåˆ†æé–‹å§‹ (è©¦è¡Œ {attempt + 1}/{max_retries}, ã‚¯ã‚¨ãƒª: {query})", Fore.MAGENTA)

                # --- â–¼â–¼â–¼ ã“ã“ã‹ã‚‰ãŒå¤‰æ›´ç®‡æ‰€ â–¼â–¼â–¼ ---
                url = f"{self.base_url}/chat/completions"
                
                headers = {
                    "Authorization": f"Bearer {self.openrouter_api_key}",
                    "Content-Type": "application/json",
                    "HTTP-Referer": "https://realtime-news-analyzer.com", # ä»»æ„ãƒ˜ãƒƒãƒ€ãƒ¼
                    "X-Title": "Real-time News Analyzer", # ä»»æ„ãƒ˜ãƒƒãƒ€ãƒ¼
                }
                
                payload = {
                    "model": "mistralai/mistral-small",
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 1500,
                    "temperature": 0.3
                }

                response = requests.post(url, headers=headers, json=payload, timeout=60)
                response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã‚‹
                
                response_data = response.json()
                result = response_data['choices'][0]['message']['content']
                # --- â–²â–²â–² ã“ã“ã¾ã§ãŒå¤‰æ›´ç®‡æ‰€ â–²â–²â–² ---

                if len(result.strip()) <= 0:
                    raise ValueError(result)

                self.colored_print(f"âœ… LLMåˆ†æå®Œäº† (ã‚¯ã‚¨ãƒª: {query})", Fore.GREEN)
                return result # æˆåŠŸã—ãŸã‚‰çµæœã‚’è¿”ã—ã¦ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹

            except Exception as e:
                # æœ€å¾Œã®ãƒªãƒˆãƒ©ã‚¤ã§ã‚‚å¤±æ•—ã—ãŸå ´åˆ
                if attempt + 1 == max_retries:
                    self.colored_print(f"âŒ LLMåˆ†æãŒ{max_retries}å›ã™ã¹ã¦å¤±æ•—ã—ã¾ã—ãŸ (ã‚¯ã‚¨ãƒª: {query}): {e}", Fore.RED, Style.BRIGHT)
                    return "" # æœ€çµ‚çš„ã«å¤±æ•—ã—ãŸã‚‰ç©ºæ–‡å­—ã‚’è¿”ã™
                
                # æ¬¡ã®ãƒªãƒˆãƒ©ã‚¤ã¾ã§ã®å¾…æ©Ÿæ™‚é–“ã‚’è¨ˆç®— (ã‚¨ã‚¯ã‚¹ãƒãƒãƒ³ã‚·ãƒ£ãƒ«ãƒ»ãƒãƒƒã‚¯ã‚ªãƒ• + ã‚¸ãƒƒã‚¿ãƒ¼)
                # 2ã®ã¹ãä¹—ã§å¾…æ©Ÿæ™‚é–“ãŒå¢—ãˆã€æœ€å¤§60ç§’ã«åˆ¶é™
                backoff_time = (2 ** attempt) + random.uniform(0, 1)
                sleep_time = min(backoff_time, 60)

                self.colored_print(f"âš ï¸  LLMåˆ†æã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}/{max_retries}): {e}", Fore.YELLOW)
                self.colored_print(f"â³ {sleep_time:.1f}ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™...", Fore.YELLOW)
                time.sleep(sleep_time)
        
        # ãƒ«ãƒ¼ãƒ—ãŒæ­£å¸¸ã«å®Œäº†ã™ã‚‹ã“ã¨ã¯åŸºæœ¬çš„ã«ãªã„ãŒã€å¿µã®ãŸã‚
        return ""

    def _create_global_analysis_prompt(self, today, query, news_text):
        """ä¸–ç•Œæƒ…å‹¢åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        return f"""
Today's Date: {today}
Search Query: "{query}"

Please analyze the following news articles and assess their potential impact on the Chinese economy and stock market.

News Articles:
{news_text}

Instructions:
1. Focus only on news that could meaningfully impact Chinese stocks or economy
2. Output your analysis in JAPANESE using this format:

ã€ã‚¯ã‚¨ãƒªã€Œ{query}ã€ã®åˆ†æçµæœã€‘

**å½±éŸ¿åº¦: é«˜/ä¸­/ä½**

**ãƒã‚¸ãƒ†ã‚£ãƒ–è¦å› :**
- yyyy/mm/dd: [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«] \n â†’ è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥æœ¬èªè¨³ï¼‰ã¨ãã®å½±éŸ¿

**ãƒã‚¬ãƒ†ã‚£ãƒ–è¦å› :**
- yyyy/mm/dd: [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«] \n â†’ è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥æœ¬èªè¨³ï¼‰ã¨ãã®å½±éŸ¿

**æ³¨ç›®ã™ã¹ãè¨˜äº‹:**
- yyyy/mm/dd: [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«è¦ç´„] \n â†’ ï¼ˆæ—¥æœ¬èªè¨³ï¼‰] â†’ è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥æœ¬èªè¨³ï¼‰ã¨ä¸­å›½æ ªã¸ã®å½±éŸ¿

**ç·åˆè©•ä¾¡:**
[ã“ã®æ¤œç´¢çµæœå…¨ä½“ã®ä¸­å›½çµŒæ¸ˆãƒ»æ ªå¼å¸‚å ´ã¸ã®å½±éŸ¿åº¦åˆã„ã¨æ–¹å‘æ€§]

Important Notes:
- Output everything in JAPANESE
- Focus on indirect impacts through trade, policy, global demand, etc.
- If no relevant impact is found, state "ä¸­å›½çµŒæ¸ˆã¸ã®ç›´æ¥çš„å½±éŸ¿ã¯é™å®šçš„"
- Be specific about the transmission mechanism to Chinese markets
"""

    def _create_china_analysis_prompt(self, today, query, news_text):
        """ä¸­å›½æƒ…å‹¢åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        companies_text = ", ".join(self.target_companies)
        
        return f"""
Today's Date: {today}
Search Query: "{query}"
Target Companies: {companies_text}

Please analyze the following China-related news and assess their impact on Chinese stocks.

News Articles:
{news_text}

Instructions:
1. Focus on direct impacts to Chinese companies and economy
2. Output your analysis in JAPANESE using this format:

ã€ã‚¯ã‚¨ãƒªã€Œ{query}ã€ã®åˆ†æçµæœã€‘

**å½±éŸ¿åº¦: é«˜/ä¸­/ä½**

**æ ªä¾¡ä¸Šæ˜‡è¦å› :**
- yyyy/mm/dd: [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«] \n â†’ è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥æœ¬èªè¨³ï¼‰ã¨ãã®å½±éŸ¿

**æ ªä¾¡ä¸‹è½è¦å› :**
- yyyy/mm/dd: [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«] \n â†’ è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥æœ¬èªè¨³ï¼‰ã¨ãã®å½±éŸ¿

**å€‹åˆ¥ä¼æ¥­ã¸ã®å½±éŸ¿:**
- [ä¼æ¥­å]: [ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¦‚è¦] \n â†’ è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥æœ¬èªè¨³ï¼‰ã¨å½±éŸ¿: ä¸Šæ˜‡/ä¸‹è½/ä¸­ç«‹

**æ³¨ç›®ã™ã¹ãè¨˜äº‹:**
- yyyy/mm/dd: [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«] \n â†’  è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥æœ¬èªè¨³ï¼‰ã¨å¸‚å ´å½±éŸ¿: [èª¬æ˜]

**ç·åˆè©•ä¾¡:**
[ã“ã®æ¤œç´¢çµæœå…¨ä½“ã®ä¸­å›½æ ªå¼å¸‚å ´ã¸ã®å½±éŸ¿åº¦åˆã„ã¨æ–¹å‘æ€§]

Important Notes:
- Output everything in JAPANESE
- Consider policy changes, regulations, economic indicators
- Focus on our target companies when mentioned
- If no significant impact, state "å¸‚å ´ã¸ã®å½±éŸ¿ã¯é™å®šçš„"
"""

    def search_and_analyze_realtime(self, queries, analysis_type="global", category_name=""):
        """æ¤œç´¢ã¨åˆ†æã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å®Ÿè¡Œ"""
        self.colored_print(f"\n{'='*60}", Fore.BLUE, Style.BRIGHT)
        self.colored_print(f" {datetime.now().strftime('%Y/%m/%d')} {category_name} - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æé–‹å§‹", Fore.BLUE, Style.BRIGHT)
        self.colored_print(f"{'='*60}", Fore.BLUE, Style.BRIGHT)
        
        analysis_results = []
        
        for i, query in enumerate(queries, 1):
            self.colored_print(f"\n[{i}/{len(queries)}] ğŸ”„ å‡¦ç†ä¸­: \"{query}\"", Fore.CYAN, Style.BRIGHT)
            
            # 1. ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢
            news_data = self.search_google_news_single(query, max_results=25)
            
            # 2. å³åº§ã«LLMåˆ†æ
            if news_data:
                analysis_result = self.analyze_news_with_llm(news_data, query, analysis_type)
                if analysis_result:
                    analysis_results.append({
                        'query': query,
                        'analysis': analysis_result,
                        'news_count': len(news_data)
                    })
                    
                    # åˆ†æçµæœã‚’å³åº§ã«è¡¨ç¤º
                    self.colored_print(f"\nğŸ“Š åˆ†æçµæœ (ã‚¯ã‚¨ãƒª: {query})", Fore.GREEN, Style.BRIGHT)
                    print(analysis_result)
                    
            else:
                self.colored_print(f"âš ï¸  ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: \"{query}\"", Fore.YELLOW)
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼ˆæœ€å¾Œã®ã‚¯ã‚¨ãƒªä»¥å¤–ï¼‰
            if i < len(queries):
                wait_time = random.uniform(8.0, 12.0)
                self.colored_print(f"â³ {wait_time:.1f}ç§’å¾…æ©Ÿä¸­...", Fore.YELLOW)
                time.sleep(wait_time)
        
        # ã‚«ãƒ†ã‚´ãƒªå…¨ä½“ã®çµæœä¿å­˜
        if analysis_type == "global":
            self.global_analysis_results.extend(analysis_results)
        else:
            self.china_analysis_results.extend(analysis_results)
        
        self.colored_print(f"\nâœ… {category_name} å®Œäº†: {len(analysis_results)}ä»¶ã®åˆ†æçµæœ", Fore.GREEN, Style.BRIGHT)
        return analysis_results

    def generate_comprehensive_summary(self):
        """å…¨åˆ†æçµæœã‚’çµ±åˆã—ãŸæœ€çµ‚åˆ¤æ–­"""
        if not self.global_analysis_results and not self.china_analysis_results:
            self.colored_print("âš ï¸  çµ±åˆã§ãã‚‹åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“", Fore.YELLOW)
            return
        
        today = datetime.now().strftime("%Y/%m/%d")
        
        # ä¸–ç•Œæƒ…å‹¢åˆ†æçµæœã®çµ±åˆ
        global_summary = "\n".join([
            f"ã€{result['query']}ã€‘\n{result['analysis']}\n" 
            for result in self.global_analysis_results
        ])
        
        # ä¸­å›½æƒ…å‹¢åˆ†æçµæœã®çµ±åˆ
        china_summary = "\n".join([
            f"ã€{result['query']}ã€‘\n{result['analysis']}\n" 
            for result in self.china_analysis_results
        ])
        
        prompt = f"""
Today's Date: {today}

Please provide a comprehensive investment judgment by integrating all the following analysis results.

ã€Global Situation Analysis Resultsã€‘
{global_summary}

ã€China Situation Analysis Resultsã€‘
{china_summary}

Instructions:
Create a final comprehensive judgment in JAPANESE using this format:

ã€ğŸ¯ æœ€çµ‚æŠ•è³‡åˆ¤æ–­ã€‘
**ç·åˆåˆ¤æ–­: å¼·æ°—/å¼±æ°—/ä¸­ç«‹**
**ç¢ºä¿¡åº¦: é«˜/ä¸­/ä½**

ã€ğŸ“Š åˆ¤æ–­æ ¹æ‹ ã€‘
**ä¸–ç•Œæƒ…å‹¢ã‹ã‚‰ã®å½±éŸ¿:**
- [ä¸–ç•ŒçµŒæ¸ˆãŒä¸­å›½æ ªã«ä¸ãˆã‚‹ä¸»è¦ãªå½±éŸ¿è¦å› ]

**ä¸­å›½å›½å†…æƒ…å‹¢:**
- [ä¸­å›½å›½å†…ã®é‡è¦ãªãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–è¦å› ]

**å€‹åˆ¥ä¼æ¥­è¦å› :**
- [å¯¾è±¡ä¼æ¥­ã«é–¢ã™ã‚‹é‡è¦ãªææ–™]

ã€ğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‘
- [å…·ä½“çš„ãªæŠ•è³‡è¡Œå‹•ã®ææ¡ˆ]

ã€âš ï¸  ä¸»è¦ãƒªã‚¹ã‚¯è¦å› ã€‘
- [ä»Šå¾Œæ³¨æ„ã™ã¹ãé‡è¦ãªãƒªã‚¹ã‚¯]

ã€ğŸ“ˆ ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥è¦‹é€šã—ã€‘
- [æŠ€è¡“æ ªã€æ¶ˆè²»é–¢é€£æ ªã€ä¸å‹•ç”£é–¢é€£æ ªç­‰ã®è¦‹é€šã—]

Important Notes:
- Output everything in JAPANESE
- Balance both global and domestic factors
- Provide actionable insights
- Consider risk-reward balance
"""
        try:
            self.colored_print(f"\n{'='*60}", Fore.RED, Style.BRIGHT)
            self.colored_print("  ğŸ¯ æœ€çµ‚çµ±åˆåˆ†æå®Ÿè¡Œä¸­", Fore.RED, Style.BRIGHT)
            self.colored_print(f"{'='*60}", Fore.RED, Style.BRIGHT)
            
            # --- â–¼â–¼â–¼ ã“ã“ã‹ã‚‰ãŒå¤‰æ›´ç®‡æ‰€ â–¼â–¼â–¼ ---
            url = f"{self.base_url}/chat/completions"
            
            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://realtime-news-analyzer.com", # ä»»æ„ãƒ˜ãƒƒãƒ€ãƒ¼
                "X-Title": "Real-time News Analyzer Final Summary", # ä»»æ„ãƒ˜ãƒƒãƒ€ãƒ¼
            }
            
            payload = {
                "model": "mistralai/mistral-small",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 2000,
                "temperature": 0.2
            }
            
            response = requests.post(url, headers=headers, json=payload, timeout=90)
            response.raise_for_status()
            
            response_data = response.json()
            final_result = response_data['choices'][0]['message']['content']
            # --- â–²â–²â–² ã“ã“ã¾ã§ãŒå¤‰æ›´ç®‡æ‰€ â–²â–²â–² ---
            
            self.colored_print(f"\nğŸ¯ æœ€çµ‚æŠ•è³‡åˆ¤æ–­", Fore.RED, Style.BRIGHT)
            print(final_result)
            
            # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
            total_global = len(self.global_analysis_results)
            total_china = len(self.china_analysis_results)
            total_news = sum(r['news_count'] for r in self.global_analysis_results + self.china_analysis_results)
            
            self.colored_print(f"\nğŸ“Š åˆ†æçµ±è¨ˆ", Fore.BLUE, Style.BRIGHT)
            self.colored_print(f"ä¸–ç•Œæƒ…å‹¢ã‚¯ã‚¨ãƒª: {total_global}ä»¶", Fore.WHITE)
            self.colored_print(f"ä¸­å›½æƒ…å‹¢ã‚¯ã‚¨ãƒª: {total_china}ä»¶", Fore.WHITE)
            self.colored_print(f"ç·è¨˜äº‹æ•°: {total_news}ä»¶", Fore.WHITE)
            
        except Exception as e:
            self.colored_print(f"âŒ æœ€çµ‚åˆ†æã‚¨ãƒ©ãƒ¼: {e}", Fore.RED)

    def run_realtime_analysis(self):
        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ—ãƒ­ã‚»ã‚¹"""
        self.colored_print("="*70, Fore.MAGENTA, Style.BRIGHT)
        self.colored_print(f"    ğŸš€{datetime.now().strftime('%Y/%m/%d')} ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æã‚·ã‚¹ãƒ†ãƒ ", Fore.MAGENTA, Style.BRIGHT)
        self.colored_print("="*70, Fore.MAGENTA, Style.BRIGHT)
        self.colored_print(f"ğŸ• é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y/%m/%d %H:%M:%S')}", Fore.WHITE)
        self.colored_print("ğŸ“ æ¤œç´¢â†’åˆ†æâ†’çµæœè¡¨ç¤ºã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å®Ÿè¡Œ", Fore.WHITE)
        
        # ä¸–ç•Œæƒ…å‹¢é–¢é€£ã‚¯ã‚¨ãƒª
        global_queries = [
            "US economy news", 
            # "Federal Reserve interest rate",
            # "European economic outlook",
            # "global inflation trends",
            "US China trade relations",
            # "geopolitical risks markets"
        ]
        
        # ä¸­å›½æƒ…å‹¢é–¢é€£ã‚¯ã‚¨ãƒª  
        china_queries = [
            "China economy news",
            "Chinese stock market news",
            # "China property market",
            # "China tech regulation",
            # "Alibaba Tencent news",
            # "BYD Xiaomi news today"
        ]
        
        # 1. ä¸–ç•Œæƒ…å‹¢ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æ
        self.search_and_analyze_realtime(
            global_queries, 
            analysis_type="global", 
            category_name="ğŸŒ ä¸–ç•Œæƒ…å‹¢"
        )
        
        # 2. ä¸­å›½æƒ…å‹¢ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æ
        self.search_and_analyze_realtime(
            china_queries, 
            analysis_type="china", 
            category_name="ğŸ‡¨ğŸ‡³ ä¸­å›½æƒ…å‹¢"
        )
        
        # 3. æœ€çµ‚çµ±åˆåˆ†æ
        self.generate_comprehensive_summary()
        
        self.colored_print(f"\n{'='*70}", Fore.MAGENTA, Style.BRIGHT)
        self.colored_print(f"âœ… åˆ†æå®Œäº† - {datetime.now().strftime('%H:%M:%S')}", Fore.MAGENTA, Style.BRIGHT)
        self.colored_print(f"{'='*70}", Fore.MAGENTA, Style.BRIGHT)


def main():
    import os
    
    # APIã‚­ãƒ¼è¨­å®š
    api_key = os.getenv("OPENROUTER_API_KEY")
    
    if not api_key:
        print(f"{Fore.RED}âŒ ã‚¨ãƒ©ãƒ¼: OpenRouter APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼å®Ÿè¡Œ
    analyzer = RealTimeNewsAnalyzer(api_key)
    analyzer.run_realtime_analysis()


if __name__ == "__main__":
    main()