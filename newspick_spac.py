import requests
from bs4 import BeautifulSoup
import time
import random
from datetime import datetime, timedelta
import re
from urllib.parse import quote
import json
from colorama import Fore, Style, init

# ã‚«ãƒ©ãƒ¼å‡ºåŠ›ã®åˆæœŸåŒ–
init(autoreset=True)

class IndexPredictionAnalyzer:
    def __init__(self, openrouter_api_key):
        self.openrouter_api_key = openrouter_api_key
        self.base_url = "https://openrouter.ai/api/v1"
        self.target_indices = ["MSCI ACWI", "S&P500"]
        self.us_economy_results = []
        self.msci_acwi_results = []
        self.sp500_results = []
        
    def colored_print(self, text, color=Fore.WHITE, style=Style.NORMAL):
        """ã‚«ãƒ©ãƒ¼å‡ºåŠ›ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
        print(f"{style}{color}{text}{Style.RESET_ALL}")
        
    def search_google_news_single(self, query, max_results=25):
        """å˜ä¸€ã‚¯ã‚¨ãƒªã§Google Newsã‹ã‚‰è¨˜äº‹ã‚’å–å¾—"""
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept-Language': 'en-US,en;q=0.9,ja;q=0.8',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        base_url = "https://news.google.com/search"
        params = {
            'q': query,
            'hl': 'en-US',
            'gl': 'US',
            'ceid': 'US:en'
        }
        
        try:
            self.colored_print(f"ğŸ” æ¤œç´¢å®Ÿè¡Œ: \"{query}\"", Fore.CYAN, Style.BRIGHT)
            response = requests.get(base_url, params=params, headers=headers, timeout=20)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            articles = soup.find_all('article')
            
            self.colored_print(f"ğŸ“° ç™ºè¦‹ã•ã‚ŒãŸè¨˜äº‹æ•°: {len(articles)}", Fore.YELLOW)
            
            news_items = []
            one_week_ago = datetime.now() - timedelta(days=7)
            
            for i, article in enumerate(articles[:max_results]):
                try:
                    # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—ï¼ˆè¤‡æ•°ã®ã‚»ãƒ¬ã‚¯ã‚¿ã‚’è©¦è¡Œï¼‰
                    title = ""
                    title_selectors = ['a.JtKRv', 'a[data-n-au]', 'h3 a', 'h4 a', 'article a']
                    for selector in title_selectors:
                        title_tag = article.select_one(selector)
                        if title_tag and title_tag.get_text(strip=True):
                            title = title_tag.get_text(strip=True)
                            break
                    
                    if not title:
                        continue
                    
                    # ãƒªãƒ³ã‚¯å–å¾—
                    link = ""
                    link_selectors = ['a.WwrzSb', 'a.JtKRv', 'a[data-n-au]']
                    for selector in link_selectors:
                        link_tag = article.select_one(selector)
                        if link_tag and link_tag.get('href'):
                            link = link_tag['href']
                            if link.startswith('./'):
                                link = 'https://news.google.com' + link[1:]
                            elif link.startswith('/'):
                                link = 'https://news.google.com' + link
                            break
                    
                    # ã‚½ãƒ¼ã‚¹å–å¾—
                    source = "Unknown"
                    source_selectors = ['div.vr1PYe', '.CEMjEf', 'span.vr1PYe']
                    for selector in source_selectors:
                        source_tag = article.select_one(selector)
                        if source_tag and source_tag.get_text(strip=True):
                            source = source_tag.get_text(strip=True)
                            break
                    
                    # æ™‚é–“å–å¾—
                    time_text = "Unknown"
                    time_tag = article.select_one('time')
                    if time_tag:
                        time_text = time_tag.get_text(strip=True)
                    
                    # ã‚¹ãƒ‹ãƒšãƒƒãƒˆå–å¾—
                    snippet = ""
                    snippet_selectors = ['span.fCU_i', '.Rai5ob', '.xBjCHd', 'div[data-snippet]']
                    for selector in snippet_selectors:
                        snippet_tag = article.select_one(selector)
                        if snippet_tag and snippet_tag.get_text(strip=True):
                            snippet = snippet_tag.get_text(strip=True)
                            break
                    
                    # æ—¥ä»˜æ¨å®š
                    estimated_date = self._estimate_date_from_time_text(time_text)
                    
                    # 1é€±é–“ä»¥å†…ã‹ãƒã‚§ãƒƒã‚¯
                    if estimated_date and estimated_date < one_week_ago:
                        continue
                    
                    news_item = {
                        'title': title,
                        'link': link,
                        'source': source,
                        'time': time_text,
                        'snippet': snippet,
                        'date': estimated_date.strftime('%Y/%m/%d') if estimated_date else 'Unknown',
                        'query': query
                    }
                    
                    news_items.append(news_item)
                    
                except Exception as e:
                    self.colored_print(f"è¨˜äº‹{i+1}ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", Fore.RED)
                    continue
            
            self.colored_print(f"âœ… å–å¾—å®Œäº†: {len(news_items)}ä»¶ã®è¨˜äº‹", Fore.GREEN)
            
            # å–å¾—ã—ãŸè¨˜äº‹ã®ä¸€è¦§è¡¨ç¤ºï¼ˆæœ€åˆã®3ä»¶ï¼‰
            for i, item in enumerate(news_items[:3], 1):
                self.colored_print(f"  {i}. {item['title'][:70]}...", Fore.WHITE)
                self.colored_print(f"    ğŸ“… {item['time']} | ğŸ¢ {item['source']}", Fore.LIGHTBLACK_EX)
            
            if len(news_items) > 3:
                self.colored_print(f"    ... ä»– {len(news_items) - 3} ä»¶", Fore.LIGHTBLACK_EX)
            
            return news_items
            
        except requests.exceptions.RequestException as e:
            self.colored_print(f"âŒ ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}", Fore.RED)
            return []
        except Exception as e:
            self.colored_print(f"âŒ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}", Fore.RED)
            return []

    def _estimate_date_from_time_text(self, time_text):
        """æ™‚é–“ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ—¥ä»˜ã‚’æ¨å®š"""
        if not time_text or time_text == "Unknown":
            return datetime.now()
        
        now = datetime.now()
        time_text_lower = time_text.lower()
        
        try:
            # åˆ†å˜ä½
            if 'minute' in time_text_lower or 'min' in time_text_lower:
                minutes = re.search(r'(\d+)', time_text)
                if minutes:
                    return now - timedelta(minutes=int(minutes.group(1)))
            
            # æ™‚é–“å˜ä½
            elif 'hour' in time_text_lower:
                hours = re.search(r'(\d+)', time_text)
                if hours:
                    return now - timedelta(hours=int(hours.group(1)))
            
            # æ—¥å˜ä½
            elif 'day' in time_text_lower or 'yesterday' in time_text_lower:
                if 'yesterday' in time_text_lower:
                    return now - timedelta(days=1)
                days = re.search(r'(\d+)', time_text)
                if days:
                    return now - timedelta(days=int(days.group(1)))
            
            # é€±å˜ä½
            elif 'week' in time_text_lower:
                weeks = re.search(r'(\d+)', time_text)
                if weeks:
                    return now - timedelta(weeks=int(weeks.group(1)))
    
        except Exception:
            pass
        
        return now

    def analyze_news_with_llm(self, news_data, query, analysis_type="us_economy"):
        """LLMã‚’ä½¿ç”¨ã—ã¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åˆ†æï¼ˆæœ€å¤§15å›ã®ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰"""
        if not news_data:
            return ""

        today = datetime.now().strftime("%Y/%m/%d")
        news_text = "\n".join([
            f"Date: {item['date']}\nTitle: {item['title']}\nSource: {item['source']}\nSnippet: {item['snippet']}\n---"
            for item in news_data
        ])

        if analysis_type == "us_economy":
            prompt = self._create_us_economy_analysis_prompt(today, query, news_text)
        elif analysis_type == "msci_acwi":
            prompt = self._create_msci_acwi_analysis_prompt(today, query, news_text)
        elif analysis_type == "sp500":
            prompt = self._create_sp500_analysis_prompt(today, query, news_text)

        max_retries = 15
        for attempt in range(max_retries):
            try:
                self.colored_print(f"ğŸ¤– LLMåˆ†æé–‹å§‹ (è©¦è¡Œ {attempt + 1}/{max_retries}, ã‚¯ã‚¨ãƒª: {query})", Fore.MAGENTA)

                url = f"{self.base_url}/chat/completions"
                
                headers = {
                    "Authorization": f"Bearer {self.openrouter_api_key}",
                    "Content-Type": "application/json",
                    "HTTP-Referer": "https://index-prediction-analyzer.com",
                    "X-Title": "Index Prediction Analyzer",
                }
                
                payload = {
                    "model": "mistralai/mistral-small",
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 3500,
                    "temperature": 0.3
                }

                response = requests.post(url, headers=headers, json=payload, timeout=60)
                response.raise_for_status()
                
                response_data = response.json()
                result = response_data['choices'][0]['message']['content']

                if len(result.strip()) <= 0:
                    raise ValueError(result)

                self.colored_print(f"âœ… LLMåˆ†æå®Œäº† (ã‚¯ã‚¨ãƒª: {query})", Fore.GREEN)
                return result

            except Exception as e:
                if attempt + 1 == max_retries:
                    self.colored_print(f"âŒ LLMåˆ†æãŒ{max_retries}å›ã™ã¹ã¦å¤±æ•—ã—ã¾ã—ãŸ (ã‚¯ã‚¨ãƒª: {query}): {e}", Fore.RED, Style.BRIGHT)
                    return ""
                
                backoff_time = (2 ** attempt) + random.uniform(0, 1)
                sleep_time = min(backoff_time, 60)

                self.colored_print(f"âš ï¸  LLMåˆ†æã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}/{max_retries}): {e}", Fore.YELLOW)
                self.colored_print(f"â³ {sleep_time:.1f}ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™...", Fore.YELLOW)
                time.sleep(sleep_time)
        
        return ""

    def _create_us_economy_analysis_prompt(self, today, query, news_text):
        """ç±³å›½çµŒæ¸ˆåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        return f"""
Today's Date: {today}
Search Query: "{query}"

Please analyze the following US economic news articles and assess their potential impact on MSCI ACWI and S&P 500 indices.

News Articles:
{news_text}

Instructions:
1. Focus on economic indicators, Fed policy, inflation, employment, GDP, etc.
2. Output your analysis in JAPANESE using this format:

ã€ã‚¯ã‚¨ãƒªã€Œ{query}ã€ã®ç±³å›½çµŒæ¸ˆåˆ†æã€‘

**çµŒæ¸ˆçŠ¶æ³è©•ä¾¡: è‰¯å¥½/æ™®é€š/æ‚ªåŒ–**

**æ ªå¼å¸‚å ´ã¸ã®ä¸Šæ˜‡è¦å› :**
- yyyy/mm/dd: [å½±éŸ¿åº¦] [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«(åŸæ–‡)] \n â†’ è¨˜äº‹å†…å®¹ã®æ—¥æœ¬èªè¦ç´„ã¨æ ªä¾¡ã¸ã®å½±éŸ¿

**æ ªå¼å¸‚å ´ã¸ã®ä¸‹è½è¦å› :**
- yyyy/mm/dd: [å½±éŸ¿åº¦] [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«(åŸæ–‡)] \n â†’ è¨˜äº‹å†…å®¹ã®æ—¥æœ¬èªè¦ç´„ã¨æ ªä¾¡ã¸ã®å½±éŸ¿

**Fedæ”¿ç­–ãƒ»é‡‘åˆ©é–¢é€£:**
- yyyy/mm/dd: [å½±éŸ¿åº¦] [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«(åŸæ–‡)] \n â†’ è¨˜äº‹å†…å®¹ã®æ—¥æœ¬èªè¦ç´„ã¨å¸‚å ´ã¸ã®å½±éŸ¿

**çµŒæ¸ˆæŒ‡æ¨™é–¢é€£:**
- yyyy/mm/dd: [å½±éŸ¿åº¦] [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«(åŸæ–‡)] \n â†’ è¨˜äº‹å†…å®¹ã®æ—¥æœ¬èªè¦ç´„ã¨æŒ‡æ¨™ã®æ„å‘³

**MSCI ACWI ã¸ã®å½±éŸ¿äºˆæ¸¬:**
[ç±³å›½çµŒæ¸ˆçŠ¶æ³ãŒMSCI ACWIã«ä¸ãˆã‚‹å½±éŸ¿ã®åˆ†æ]

**S&P 500 ã¸ã®å½±éŸ¿äºˆæ¸¬:**
[ç±³å›½çµŒæ¸ˆçŠ¶æ³ãŒS&P 500ã«ä¸ãˆã‚‹å½±éŸ¿ã®åˆ†æ]

**ç·åˆè©•ä¾¡:**
[ç±³å›½çµŒæ¸ˆå…¨ä½“ã®ç¾çŠ¶è©•ä¾¡ã¨ä»Šå¾Œã®è¦‹é€šã—]

Important Notes:
- Output everything in JAPANESE
- Focus on macroeconomic factors that drive broad market indices
- Consider both domestic US factors and global implications
- If limited relevant news, state "é–¢é€£ã™ã‚‹é‡è¦ãªçµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯é™å®šçš„"
"""

    def _create_msci_acwi_analysis_prompt(self, today, query, news_text):
        """MSCI ACWIåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        return f"""
Today's Date: {today}
Search Query: "{query}"

Please analyze the following news related to MSCI ACWI and assess the price movement predictions and market outlook.

News Articles:
{news_text}

Instructions:
1. Focus on MSCI ACWI index movements, predictions, and related global market factors
2. Output your analysis in JAPANESE using this format:

ã€ã‚¯ã‚¨ãƒªã€Œ{query}ã€ã®MSCI ACWIåˆ†æã€‘

**å€¤å‹•ãäºˆæ¸¬: ä¸Šæ˜‡/ä¸‹è½/æ¨ªã°ã„**
**äºˆæ¸¬ç¢ºä¿¡åº¦: é«˜/ä¸­/ä½**

**ä¸Šæ˜‡è¦å› :**
- yyyy/mm/dd: [å½±éŸ¿åº¦] [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«(åŸæ–‡)] \n â†’ è¨˜äº‹å†…å®¹ã®æ—¥æœ¬èªè¦ç´„ã¨MSCI ACWIã¸ã®å½±éŸ¿

**ä¸‹è½è¦å› :**
- yyyy/mm/dd: [å½±éŸ¿åº¦] [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«(åŸæ–‡)] \n â†’ è¨˜äº‹å†…å®¹ã®æ—¥æœ¬èªè¦ç´„ã¨MSCI ACWIã¸ã®å½±éŸ¿

**åœ°åŸŸåˆ¥å½±éŸ¿:**
- ç±³å›½: [å½±éŸ¿è¦å› ã¨MSCI ACWIã¸ã®å¯„ä¸]
- æ¬§å·: [å½±éŸ¿è¦å› ã¨MSCI ACWIã¸ã®å¯„ä¸]
- æ–°èˆˆå›½: [å½±éŸ¿è¦å› ã¨MSCI ACWIã¸ã®å¯„ä¸]
- ãã®ä»–: [å½±éŸ¿è¦å› ã¨MSCI ACWIã¸ã®å¯„ä¸]

**ã‚»ã‚¯ã‚¿ãƒ¼åˆ¥å½±éŸ¿:**
- [ä¸»è¦ã‚»ã‚¯ã‚¿ãƒ¼ã®MSCI ACWIæ§‹æˆæ¯”ç‡ã¸ã®å½±éŸ¿åˆ†æ]

**å°‚é–€å®¶äºˆæ¸¬ãƒ»ã‚¢ãƒŠãƒªã‚¹ãƒˆè¦‹è§£:**
- yyyy/mm/dd: [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«(åŸæ–‡)] \n â†’ å°‚é–€å®¶ã®äºˆæ¸¬å†…å®¹ã¨æ ¹æ‹ ã®æ—¥æœ¬èªè¦ç´„

**æŠ€è¡“çš„åˆ†æè¦å› :**
- [ãƒãƒ£ãƒ¼ãƒˆåˆ†æã€ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ç­‰ã®æƒ…å ±]

**ä»Šå¾Œ1ãƒ¶æœˆã®è¦‹é€šã—:**
[çŸ­æœŸçš„ãªMSCI ACWIã®å€¤å‹•ãäºˆæ¸¬ã¨ä¸»è¦ãƒªã‚¹ã‚¯è¦å› ]

**ä»Šå¾Œ3ãƒ¶æœˆã®è¦‹é€šã—:**
[ä¸­æœŸçš„ãªMSCI ACWIã®å€¤å‹•ãäºˆæ¸¬ã¨æ§‹é€ çš„è¦å› ]

Important Notes:
- Output everything in JAPANESE
- Focus specifically on MSCI ACWI index performance and predictions
- Include global diversification aspects
- Consider both developed and emerging market factors
- If no direct MSCI ACWI news, analyze from global equity perspective
"""

    def _create_sp500_analysis_prompt(self, today, query, news_text):
        """S&P500åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        return f"""
Today's Date: {today}
Search Query: "{query}"

Please analyze the following news related to S&P 500 and assess the price movement predictions and market outlook.

News Articles:
{news_text}

Instructions:
1. Focus on S&P 500 index movements, predictions, and US market factors
2. Output your analysis in JAPANESE using this format:

ã€ã‚¯ã‚¨ãƒªã€Œ{query}ã€ã®S&P 500åˆ†æã€‘

**å€¤å‹•ãäºˆæ¸¬: ä¸Šæ˜‡/ä¸‹è½/æ¨ªã°ã„**
**äºˆæ¸¬ç¢ºä¿¡åº¦: é«˜/ä¸­/ä½**

**ä¸Šæ˜‡è¦å› :**
- yyyy/mm/dd: [å½±éŸ¿åº¦] [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«(åŸæ–‡)] \n â†’ è¨˜äº‹å†…å®¹ã®æ—¥æœ¬èªè¦ç´„ã¨S&P 500ã¸ã®å½±éŸ¿

**ä¸‹è½è¦å› :**
- yyyy/mm/dd: [å½±éŸ¿åº¦] [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«(åŸæ–‡)] \n â†’ è¨˜äº‹å†…å®¹ã®æ—¥æœ¬èªè¦ç´„ã¨S&P 500ã¸ã®å½±éŸ¿

**ä¸»è¦ä¼æ¥­ãƒ»ã‚»ã‚¯ã‚¿ãƒ¼å½±éŸ¿:**
- ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼: [AAPL, MSFT, GOOGLç­‰ã¸ã®å½±éŸ¿]
- ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢: [ä¸»è¦ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ä¼æ¥­ã¸ã®å½±éŸ¿]
- é‡‘è: [éŠ€è¡Œãƒ»ä¿é™ºã‚»ã‚¯ã‚¿ãƒ¼ã¸ã®å½±éŸ¿]
- ã‚¨ãƒãƒ«ã‚®ãƒ¼: [çŸ³æ²¹ãƒ»ã‚¬ã‚¹ä¼æ¥­ã¸ã®å½±éŸ¿]
- ãã®ä»–é‡è¦ã‚»ã‚¯ã‚¿ãƒ¼: [å½±éŸ¿ã®ã‚ã‚‹æ¥­ç¨®]

**ä¼æ¥­æ±ºç®—ãƒ»æ¥­ç¸¾é–¢é€£:**
- yyyy/mm/dd: [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«(åŸæ–‡)] \n â†’ ä¸»è¦ä¼æ¥­ã®æ±ºç®—ãŒS&P 500ã«ä¸ãˆã‚‹å½±éŸ¿

**å°‚é–€å®¶äºˆæ¸¬ãƒ»ã‚¢ãƒŠãƒªã‚¹ãƒˆè¦‹è§£:**
- yyyy/mm/dd: [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«(åŸæ–‡)] \n â†’ å°‚é–€å®¶ã®äºˆæ¸¬å†…å®¹ã¨ç›®æ¨™å€¤ã®æ—¥æœ¬èªè¦ç´„

**æŠ€è¡“çš„åˆ†æè¦å› :**
- [ãƒãƒ£ãƒ¼ãƒˆåˆ†æã€ç§»å‹•å¹³å‡ç·šã€ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ç­‰]

**ãƒã‚¯ãƒ­çµŒæ¸ˆè¦å› :**
- [Fedæ”¿ç­–ã€é›‡ç”¨çµ±è¨ˆã€ã‚¤ãƒ³ãƒ•ãƒ¬æŒ‡æ¨™ç­‰ã®S&P 500ã¸ã®å½±éŸ¿]

**ä»Šå¾Œ1ãƒ¶æœˆã®è¦‹é€šã—:**
[çŸ­æœŸçš„ãªS&P 500ã®å€¤å‹•ãäºˆæ¸¬ã¨ä¸»è¦ãƒªã‚¹ã‚¯è¦å› ]

**ä»Šå¾Œ3ãƒ¶æœˆã®è¦‹é€šã—:**
[ä¸­æœŸçš„ãªS&P 500ã®å€¤å‹•ãäºˆæ¸¬ã¨æ§‹é€ çš„è¦å› ]

**ç›®æ¨™ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸:**
[ã‚¢ãƒŠãƒªã‚¹ãƒˆã«ã‚ˆã‚‹ç›®æ¨™ä¾¡æ ¼ã‚„äºˆæƒ³ãƒ¬ãƒ³ã‚¸]

Important Notes:
- Output everything in JAPANESE  
- Focus specifically on S&P 500 index performance and predictions
- Include major component stocks impact
- Consider both fundamental and technical factors
- Provide specific price targets when available
"""

    def search_and_analyze_realtime(self, queries, analysis_type, category_name=""):
        """æ¤œç´¢ã¨åˆ†æã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å®Ÿè¡Œ"""
        self.colored_print(f"\n{'='*50}", Fore.BLUE, Style.BRIGHT)
        self.colored_print(f"{datetime.now().strftime('%Y/%m/%d')} {category_name} - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æé–‹å§‹", Fore.BLUE, Style.BRIGHT)
        self.colored_print(f"{'='*50}", Fore.BLUE, Style.BRIGHT)
        
        analysis_results = []
        
        for i, query in enumerate(queries, 1):
            self.colored_print(f"\n[{i}/{len(queries)}] ğŸ”„ å‡¦ç†ä¸­: \"{query}\"", Fore.CYAN, Style.BRIGHT)
            
            # 1. ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢
            news_data = self.search_google_news_single(query, max_results=25)
            
            # 2. å³åº§ã«LLMåˆ†æ
            if news_data:
                analysis_result = self.analyze_news_with_llm(news_data, query, analysis_type)
                if analysis_result:
                    analysis_results.append({
                        'query': query,
                        'analysis': analysis_result,
                        'news_count': len(news_data)
                    })
                    
                    # åˆ†æçµæœã‚’å³åº§ã«è¡¨ç¤º
                    self.colored_print(f"\nğŸ“Š åˆ†æçµæœ (ã‚¯ã‚¨ãƒª: {query})", Fore.GREEN, Style.BRIGHT)
                    print(analysis_result)
                    
            else:
                self.colored_print(f"âš ï¸  ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: \"{query}\"", Fore.YELLOW)
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ï¼ˆæœ€å¾Œã®ã‚¯ã‚¨ãƒªä»¥å¤–ï¼‰
            if i < len(queries):
                wait_time = random.uniform(8.0, 12.0)
                self.colored_print(f"â³ {wait_time:.1f}ç§’å¾…æ©Ÿä¸­...", Fore.YELLOW)
                time.sleep(wait_time)
        
        # çµæœä¿å­˜
        if analysis_type == "us_economy":
            self.us_economy_results.extend(analysis_results)
        elif analysis_type == "msci_acwi":
            self.msci_acwi_results.extend(analysis_results)
        elif analysis_type == "sp500":
            self.sp500_results.extend(analysis_results)
        
        self.colored_print(f"\nâœ… {category_name} å®Œäº†: {len(analysis_results)}ä»¶ã®åˆ†æçµæœ", Fore.GREEN, Style.BRIGHT)
        return analysis_results

    def generate_comprehensive_summary(self):
        """å…¨åˆ†æçµæœã‚’çµ±åˆã—ãŸæœ€çµ‚åˆ¤æ–­"""
        if not any([self.us_economy_results, self.msci_acwi_results, self.sp500_results]):
            self.colored_print("âš ï¸  çµ±åˆã§ãã‚‹åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“", Fore.YELLOW)
            return
        
        today = datetime.now().strftime("%Y/%m/%d")
        
        # å„åˆ†æçµæœã®çµ±åˆ
        us_economy_summary = "\n".join([
            f"ã€{result['query']}ã€‘\n{result['analysis']}\n" 
            for result in self.us_economy_results
        ])
        
        msci_acwi_summary = "\n".join([
            f"ã€{result['query']}ã€‘\n{result['analysis']}\n" 
            for result in self.msci_acwi_results
        ])
        
        sp500_summary = "\n".join([
            f"ã€{result['query']}ã€‘\n{result['analysis']}\n" 
            for result in self.sp500_results
        ])
        
        prompt = f"""
Today's Date: {today}

Please provide comprehensive investment predictions for MSCI ACWI and S&P 500 by integrating all the following analysis results.

ã€US Economy Analysis Resultsã€‘
{us_economy_summary}

ã€MSCI ACWI Analysis Resultsã€‘
{msci_acwi_summary}

ã€S&P 500 Analysis Resultsã€‘
{sp500_summary}

Instructions:
Create a final comprehensive prediction in JAPANESE using this format:

ã€ğŸ¯ æœ€çµ‚æŠ•è³‡äºˆæ¸¬ã€‘

ã€ğŸ“ˆ MSCI ACWI äºˆæ¸¬ã€‘
**å€¤å‹•ãäºˆæ¸¬: ä¸Šæ˜‡/ä¸‹è½/æ¨ªã°ã„**
**ç¢ºä¿¡åº¦: é«˜/ä¸­/ä½**
**äºˆæƒ³å¤‰å‹•ç‡: Â±X%**
**æ ¹æ‹ :**
- [ä¸»è¦ãªä¸Šæ˜‡ãƒ»ä¸‹è½è¦å› ]

ã€ğŸ“Š S&P 500 äºˆæ¸¬ã€‘  
**å€¤å‹•ãäºˆæ¸¬: ä¸Šæ˜‡/ä¸‹è½/æ¨ªã°ã„**
**ç¢ºä¿¡åº¦: é«˜/ä¸­/ä½**
**äºˆæƒ³å¤‰å‹•ç‡: Â±X%**
**æ ¹æ‹ :**
- [ä¸»è¦ãªä¸Šæ˜‡ãƒ»ä¸‹è½è¦å› ]

ã€ğŸŒ ãƒã‚¯ãƒ­ç’°å¢ƒåˆ†æã€‘
**ç±³å›½çµŒæ¸ˆçŠ¶æ³:**
- [ç¾åœ¨ã®çµŒæ¸ˆçŠ¶æ³ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¸ã®å½±éŸ¿]

**é‡‘èæ”¿ç­–å½±éŸ¿:**
- [Fedæ”¿ç­–ãŒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿]

**ã‚°ãƒ­ãƒ¼ãƒãƒ«è¦å› :**
- [å›½éš›æƒ…å‹¢ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¸ã®å½±éŸ¿]

ã€ğŸ’¡ æŠ•è³‡æˆ¦ç•¥ææ¡ˆã€‘
**MSCI ACWI:**
- [æ¨å¥¨æŠ•è³‡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨ç†ç”±]

**S&P 500:**
- [æ¨å¥¨æŠ•è³‡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨ç†ç”±]

ã€ğŸ“… æ™‚é–“è»¸åˆ¥è¦‹é€šã—ã€‘
**1é€±é–“ä»¥å†…:**
- MSCI ACWI: [çŸ­æœŸäºˆæ¸¬]
- S&P 500: [çŸ­æœŸäºˆæ¸¬]

**1ãƒ¶æœˆä»¥å†…:**
- MSCI ACWI: [ä¸­æœŸäºˆæ¸¬]  
- S&P 500: [ä¸­æœŸäºˆæ¸¬]

**3ãƒ¶æœˆä»¥å†…:**
- MSCI ACWI: [é•·æœŸäºˆæ¸¬]
- S&P 500: [é•·æœŸäºˆæ¸¬]

ã€âš ï¸  ä¸»è¦ãƒªã‚¹ã‚¯è¦å› ã€‘
- [æ³¨æ„ã™ã¹ãä¸‹è½ãƒªã‚¹ã‚¯]

ã€ğŸš€ ä¸»è¦ä¸Šæ˜‡ã‚«ã‚¿ãƒªã‚¹ãƒˆã€‘  
- [æœŸå¾…ã§ãã‚‹ä¸Šæ˜‡è¦å› ]

ã€ğŸ“‹ ã¾ã¨ã‚ã€‘
[ä¸¡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç·åˆçš„ãªæŠ•è³‡åˆ¤æ–­]

Important Notes:
- Output everything in JAPANESE
- Provide specific percentage predictions when possible
- Balance both indices' outlooks
- Consider correlation and divergence factors
- Include actionable investment advice
"""
        
        try:
            self.colored_print(f"\n{'='*60}", Fore.RED, Style.BRIGHT)
            self.colored_print("  ğŸ¯ æœ€çµ‚çµ±åˆäºˆæ¸¬å®Ÿè¡Œä¸­", Fore.RED, Style.BRIGHT)
            self.colored_print(f"{'='*60}", Fore.RED, Style.BRIGHT)
            
            url = f"{self.base_url}/chat/completions"
            
            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://index-prediction-analyzer.com",
                "X-Title": "Index Prediction Final Summary",
            }
            
            payload = {
                "model": "mistralai/mistral-small",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 2500,
                "temperature": 0.2
            }
            
            response = requests.post(url, headers=headers, json=payload, timeout=90)
            response.raise_for_status()
            
            response_data = response.json()
            final_result = response_data['choices'][0]['message']['content']
            
            self.colored_print(f"\nğŸ¯ æœ€çµ‚æŠ•è³‡äºˆæ¸¬", Fore.RED, Style.BRIGHT)
            print(final_result)
            
            # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
            total_us = len(self.us_economy_results)
            total_acwi = len(self.msci_acwi_results)
            total_sp500 = len(self.sp500_results)
            total_news = sum(r['news_count'] for r in self.us_economy_results + self.msci_acwi_results + self.sp500_results)
            
            self.colored_print(f"\nğŸ“Š åˆ†æçµ±è¨ˆ", Fore.BLUE, Style.BRIGHT)
            self.colored_print(f"ç±³å›½çµŒæ¸ˆã‚¯ã‚¨ãƒª: {total_us}ä»¶", Fore.WHITE)
            self.colored_print(f"MSCI ACWIã‚¯ã‚¨ãƒª: {total_acwi}ä»¶", Fore.WHITE)
            self.colored_print(f"S&P 500ã‚¯ã‚¨ãƒª: {total_sp500}ä»¶", Fore.WHITE)
            self.colored_print(f"ç·è¨˜äº‹æ•°: {total_news}ä»¶", Fore.WHITE)
            
        except Exception as e:
            self.colored_print(f"âŒ æœ€çµ‚åˆ†æã‚¨ãƒ©ãƒ¼: {e}", Fore.RED)

    def run_index_prediction_analysis(self):
        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ—ãƒ­ã‚»ã‚¹"""
        self.colored_print("="*60, Fore.MAGENTA, Style.BRIGHT)
        self.colored_print(f"ğŸš€ {datetime.now().strftime('%Y/%m/%d')} MSCI ACWI & S&P500 å€¤å‹•ãäºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ", Fore.MAGENTA, Style.BRIGHT)
        self.colored_print("="*60, Fore.MAGENTA, Style.BRIGHT)
        self.colored_print(f"ğŸ• é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y/%m/%d %H:%M:%S')}", Fore.WHITE)
        self.colored_print("ğŸ“ ç±³å›½çµŒæ¸ˆâ†’å„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ†æâ†’ç·åˆäºˆæ¸¬ã®é †ã§å®Ÿè¡Œ", Fore.WHITE)
        
        # 1. ç±³å›½çµŒæ¸ˆçŠ¶æ³é–¢é€£ã‚¯ã‚¨ãƒª
        us_economy_queries = [
            "US economy news",
            "Federal Reserve interest rate decision", 
            # "US inflation data CPI",
            "US employment jobs report",
            # "US GDP economic growth"
        ]
        
        # 2. MSCI ACWIé–¢é€£ã‚¯ã‚¨ãƒª
        msci_acwi_queries = [
            "MSCI ACWI",
            "MSCI ACWI price target forecast",
            # "MSCI ACWI performance outlook",
            # "global equity market forecast",
            # "MSCI world index analysis"
        ]
        
        # 3. S&P 500é–¢é€£ã‚¯ã‚¨ãƒª
        sp500_queries = [
            "S&P 500",
            "S&P 500 price target forecast",
            # "S&P 500 price target 2025",
            # "S&P 500 technical analysis",
            # "SPX index outlook forecast",
            # "S&P 500 analyst predictions"
        ]
        
        # 1. ç±³å›½çµŒæ¸ˆçŠ¶æ³ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æ
        self.search_and_analyze_realtime(
            us_economy_queries, 
            analysis_type="us_economy", 
            category_name="ğŸ‡ºğŸ‡¸ ç±³å›½çµŒæ¸ˆçŠ¶æ³"
        )
        
        # åˆ†æé–“ã®å¾…æ©Ÿæ™‚é–“
        self.colored_print(f"\nâ³ ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ›¿ã®ãŸã‚5ç§’å¾…æ©Ÿä¸­...", Fore.YELLOW)
        time.sleep(5)
        
        # 2. MSCI ACWIã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æ
        self.search_and_analyze_realtime(
            msci_acwi_queries, 
            analysis_type="msci_acwi", 
            category_name="ğŸŒ MSCI ACWI"
        )
        
        # åˆ†æé–“ã®å¾…æ©Ÿæ™‚é–“
        self.colored_print(f"\nâ³ ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡æ›¿ã®ãŸã‚5ç§’å¾…æ©Ÿä¸­...", Fore.YELLOW)
        time.sleep(5)
        
        # 3. S&P 500ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æ
        self.search_and_analyze_realtime(
            sp500_queries, 
            analysis_type="sp500", 
            category_name="ğŸ“ˆ S&P 500"
        )
        
        # 4. æœ€çµ‚çµ±åˆäºˆæ¸¬
        self.generate_comprehensive_summary()
        
        self.colored_print(f"\n{'='*60}", Fore.MAGENTA, Style.BRIGHT)
        self.colored_print(f"âœ… äºˆæ¸¬åˆ†æå®Œäº† - {datetime.now().strftime('%H:%M:%S')}", Fore.MAGENTA, Style.BRIGHT)
        self.colored_print(f"{'='*60}", Fore.MAGENTA, Style.BRIGHT)


def main():
    import os
    
    # APIã‚­ãƒ¼è¨­å®š
    api_key = os.getenv("OPENROUTER_API_KEY")
    
    if not api_key:
        print(f"{Fore.RED}âŒ ã‚¨ãƒ©ãƒ¼: OpenRouter APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print(f"{Fore.YELLOW}ç’°å¢ƒå¤‰æ•° 'OPENROUTER_API_KEY' ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
    
    # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼å®Ÿè¡Œ
    analyzer = IndexPredictionAnalyzer(api_key)
    analyzer.run_index_prediction_analysis()


if __name__ == "__main__":
    main()